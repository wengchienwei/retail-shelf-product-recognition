{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcb4bb5",
   "metadata": {},
   "source": [
    "# Stage 1: Poduct Detection with YOLOv5\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Objective:** Detect product bounding boxes in shelf images for downstream classification\n",
    "\n",
    "**Dataset:** SKU-110K Dataset\n",
    "- 11,762 shelf images from retail environments\n",
    "- Dense object detection (avg. 147 objects/image)\n",
    "- Real-world conditions: occlusion, varied scales\n",
    "\n",
    "**Model:** YOLOv5 (pretrained on COCO dataset)\n",
    "\n",
    "**Output:** Cropped product regions for Stage 2 classification\n",
    "\n",
    "**References:**\n",
    "- Dataset: [SKU-110K GitHub](https://github.com/eg4000/SKU110K_CVPR19)\n",
    "- Model: [YOLOv5 Ultralytics](https://github.com/ultralytics/yolov5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "XoGaG0AmBvwc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22495,
     "status": "ok",
     "timestamp": 1768737570852,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "XoGaG0AmBvwc",
    "outputId": "6d497165-0b18-407a-fb96-d09a2cc41a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R3j7OHQ-WEXv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5674,
     "status": "ok",
     "timestamp": 1768737577625,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "R3j7OHQ-WEXv",
    "outputId": "dd64f5f6-9d00-49db-9e6d-1d62c645a460"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MtU5ufRNEkik",
   "metadata": {
    "id": "MtU5ufRNEkik"
   },
   "source": [
    "## Dataset Overview\n",
    "**SKU-110K** (Stock Keeping Unit - 110K) is a large-scale retail product detection dataset containing densely packed objects in shelf images.\n",
    "\n",
    "<pre style=\"font-family: 'Courier New', monospace;\">\n",
    "SKU110K_fixed/\n",
    "├── images/                           # 11,762 retail shelf images\n",
    "│   ├── train_*.jpg                  # 8,219 training images\n",
    "│   ├── val_*.jpg                    # 588 validation images\n",
    "│   └── test_*.jpg                   # 2,955 test images\n",
    "├── annotations/\n",
    "│   ├── annotations_train.csv        # Training set bounding boxes\n",
    "│   ├── annotations_val.csv          # Validation set bounding boxes\n",
    "│   ├── annotations_test.csv         # Test set bounding boxes\n",
    "│   └── readme.txt                   # Dataset documentation\n",
    "└── LICENSE.txt                       # Dataset license\n",
    "</pre>\n",
    "\n",
    "## Key Characteristics\n",
    "- **Domain**: Retail product detection in store shelves\n",
    "- **Total Images**: 11,762 high-resolution images\n",
    "- **Total Annotations**: ~1.7 million bounding boxes\n",
    "- **Challenge**: Extreme object density (avg ~147 objects per image)\n",
    "- **Object Class**: Single class - \"Product\" (all retail items)\n",
    "\n",
    "## Annotation Format (CSV Files)\n",
    "Each row represents one bounding box with columns:\n",
    "- `image_name`: Image filename\n",
    "- `x1, y1, x2, y2`: Bounding box coordinates (top-left, bottom-right)\n",
    "- `class`: Object class (always \"object\" in this dataset)\n",
    "- `image_width, image_height`: Original image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sDNma229GjUK",
   "metadata": {
    "id": "sDNma229GjUK"
   },
   "outputs": [],
   "source": [
    "!tar -xzf \"/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed.tar.gz\" \\\n",
    "    -C \"/content/drive/MyDrive/Deep Learning Project/\" \\\n",
    "    SKU110K_fixed/annotations/annotations_train.csv \\\n",
    "    SKU110K_fixed/annotations/annotations_val.csv \\\n",
    "    SKU110K_fixed/annotations/annotations_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "VEbWk4sj33LN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8520,
     "status": "ok",
     "timestamp": 1768737625953,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "VEbWk4sj33LN",
    "outputId": "0ae4ad77-be4e-4537-d1a9-77c6aa49282f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAIN DATASET DETAILED ANALYSIS\n",
      "================================================================================\n",
      "    image_name    x1    y1    x2    y2   class  image_width  image_height\n",
      "0  train_0.jpg   208   537   422   814  object         3024          3024\n",
      "1  train_0.jpg  1268  1923  1365  2209  object         3024          3024\n",
      "2  train_0.jpg  1135  2074  1261  2166  object         3024          3024\n",
      "3  train_0.jpg  1045  2085  1122  2258  object         3024          3024\n",
      "4  train_0.jpg   976  2036  1040  2177  object         3024          3024\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1208482 entries, 0 to 1208481\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   image_name    1208482 non-null  object\n",
      " 1   x1            1208482 non-null  int64 \n",
      " 2   y1            1208482 non-null  int64 \n",
      " 3   x2            1208482 non-null  int64 \n",
      " 4   y2            1208482 non-null  int64 \n",
      " 5   class         1208482 non-null  object\n",
      " 6   image_width   1208482 non-null  int64 \n",
      " 7   image_height  1208482 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 73.8+ MB\n",
      "None\n",
      "                 x1            y1            x2            y2   image_width  \\\n",
      "count  1.208482e+06  1.208482e+06  1.208482e+06  1.208482e+06  1.208482e+06   \n",
      "mean   1.174623e+03  1.530047e+03  1.295433e+03  1.720162e+03  2.452477e+03   \n",
      "std    7.102995e+02  8.250651e+02  7.128696e+02  8.136492e+02  4.283618e+02   \n",
      "min    0.000000e+00  0.000000e+00  2.100000e+01  2.100000e+01  4.800000e+02   \n",
      "25%    5.950000e+02  8.960000e+02  7.160000e+02  1.096000e+03  2.336000e+03   \n",
      "50%    1.153000e+03  1.496000e+03  1.270000e+03  1.674000e+03  2.448000e+03   \n",
      "75%    1.703000e+03  2.105000e+03  1.822000e+03  2.286000e+03  2.448000e+03   \n",
      "max    4.129000e+03  4.714000e+03  4.321000e+03  4.905000e+03  4.320000e+03   \n",
      "\n",
      "       image_height  \n",
      "count  1.208482e+06  \n",
      "mean   3.219365e+03  \n",
      "std    6.758446e+02  \n",
      "min    6.400000e+02  \n",
      "25%    2.560000e+03  \n",
      "50%    3.264000e+03  \n",
      "75%    3.264000e+03  \n",
      "max    5.312000e+03  \n",
      "\n",
      "================================================================================\n",
      "VALIDATION DATASET DETAILED ANALYSIS\n",
      "================================================================================\n",
      "  image_name   x1    y1    x2    y2   class  image_width  image_height\n",
      "0  val_0.jpg    5  1429   219  1612  object         2336          4160\n",
      "1  val_0.jpg  467  1066   589  1330  object         2336          4160\n",
      "2  val_0.jpg  602  1085   739  1329  object         2336          4160\n",
      "3  val_0.jpg  756  1090   894  1368  object         2336          4160\n",
      "4  val_0.jpg  899  1095  1042  1376  object         2336          4160\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90968 entries, 0 to 90967\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   image_name    90968 non-null  object\n",
      " 1   x1            90968 non-null  int64 \n",
      " 2   y1            90968 non-null  int64 \n",
      " 3   x2            90968 non-null  int64 \n",
      " 4   y2            90968 non-null  int64 \n",
      " 5   class         90968 non-null  object\n",
      " 6   image_width   90968 non-null  int64 \n",
      " 7   image_height  90968 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 5.6+ MB\n",
      "None\n",
      "                 x1            y1            x2            y2   image_width  \\\n",
      "count  90968.000000  90968.000000  90968.000000  90968.000000  90968.000000   \n",
      "mean    1187.105048   1507.806547   1302.568705   1688.788695   2470.903658   \n",
      "std      703.607705    807.996569    703.754759    799.953781    444.173948   \n",
      "min        0.000000      0.000000     23.000000     34.000000   1840.000000   \n",
      "25%      617.000000    891.000000    733.000000   1076.000000   2322.000000   \n",
      "50%     1171.000000   1467.000000   1281.000000   1637.000000   2448.000000   \n",
      "75%     1707.000000   2060.000000   1818.000000   2235.000000   2560.000000   \n",
      "max     3979.000000   4730.000000   4323.000000   4850.000000   4320.000000   \n",
      "\n",
      "       image_height  \n",
      "count  90968.000000  \n",
      "mean    3160.814176  \n",
      "std      688.974285  \n",
      "min     1920.000000  \n",
      "25%     2560.000000  \n",
      "50%     3264.000000  \n",
      "75%     3264.000000  \n",
      "max     5312.000000  \n",
      "\n",
      "================================================================================\n",
      "TEST DATASET DETAILED ANALYSIS\n",
      "================================================================================\n",
      "   image_name   x1    y1   x2    y2   class  image_width  image_height\n",
      "0  test_0.jpg  120  2527  225  2764  object         2448          3264\n",
      "1  test_0.jpg  727  2269  862  2376  object         2448          3264\n",
      "2  test_0.jpg  463  2274  715  2434  object         2448          3264\n",
      "3  test_0.jpg  158  2290  283  2444  object         2448          3264\n",
      "4  test_0.jpg    0  2290  154  2456  object         2448          3264\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 431546 entries, 0 to 431545\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   image_name    431546 non-null  object\n",
      " 1   x1            431546 non-null  int64 \n",
      " 2   y1            431546 non-null  int64 \n",
      " 3   x2            431546 non-null  int64 \n",
      " 4   y2            431546 non-null  int64 \n",
      " 5   class         431546 non-null  object\n",
      " 6   image_width   431546 non-null  int64 \n",
      " 7   image_height  431546 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 26.3+ MB\n",
      "None\n",
      "                  x1             y1             x2             y2  \\\n",
      "count  431546.000000  431546.000000  431546.000000  431546.000000   \n",
      "mean     1168.410132    1542.504500    1288.764058    1733.334307   \n",
      "std       707.036595     827.102488     708.908558     815.536587   \n",
      "min         0.000000       0.000000      21.000000      45.000000   \n",
      "25%       589.000000     908.000000     710.000000    1109.000000   \n",
      "50%      1147.000000    1509.000000    1265.000000    1685.000000   \n",
      "75%      1699.000000    2118.000000    1816.000000    2297.000000   \n",
      "max      4100.000000    4721.000000    4320.000000    5168.000000   \n",
      "\n",
      "         image_width   image_height  \n",
      "count  431546.000000  431546.000000  \n",
      "mean     2448.680317    3234.240373  \n",
      "std       413.222296     677.642516  \n",
      "min       480.000000     640.000000  \n",
      "25%      2336.000000    2560.000000  \n",
      "50%      2448.000000    3264.000000  \n",
      "75%      2448.000000    3840.000000  \n",
      "max      4320.000000    5312.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "base = '/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/annotations'\n",
    "\n",
    "columns = ['image_name', 'x1', 'y1', 'x2', 'y2', 'class', 'image_width', 'image_height']\n",
    "\n",
    "train_df = pd.read_csv(f'{base}/annotations_train.csv', names=columns)\n",
    "val_df = pd.read_csv(f'{base}/annotations_val.csv', names=columns)\n",
    "test_df = pd.read_csv(f'{base}/annotations_test.csv', names=columns)\n",
    "\n",
    "# Train dataset analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAIN DATASET DETAILED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.info())\n",
    "print(train_df.describe())\n",
    "\n",
    "# Validation dataset analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VALIDATION DATASET DETAILED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(val_df.head())\n",
    "print(val_df.info())\n",
    "print(val_df.describe())\n",
    "\n",
    "# Test dataset analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST DATASET DETAILED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(test_df.head())\n",
    "print(test_df.info())\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1woS1zU3IKQK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 916
    },
    "executionInfo": {
     "elapsed": 1746,
     "status": "ok",
     "timestamp": 1768737634764,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "1woS1zU3IKQK",
    "outputId": "5e79c47b-f3c1-46ff-ea81-b1ce95619edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SKU-110K DATASET OVERVIEW\n",
      "================================================================================\n",
      "Train: 8,219 images, 1,208,482 bounding boxes\n",
      "Val:   588 images, 90,968 bounding boxes\n",
      "Test:  2,936 images, 431,546 bounding boxes\n",
      "\n",
      "================================================================================\n",
      "BOUNDING BOX ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "--- Boxes Per Image Statistics ---\n",
      "Average boxes per image: 147.04\n",
      "Median boxes per image: 138\n",
      "Min boxes per image: 1\n",
      "Max boxes per image: 576\n",
      "Std boxes per image: 42.76\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset overview\n",
    "print(\"=\" * 80)\n",
    "print(\"SKU-110K DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Train: {train_df['image_name'].nunique():,} images, {len(train_df):,} bounding boxes\")\n",
    "print(f\"Val:   {val_df['image_name'].nunique():,} images, {len(val_df):,} bounding boxes\")\n",
    "print(f\"Test:  {test_df['image_name'].nunique():,} images, {len(test_df):,} bounding boxes\")\n",
    "\n",
    "# Bounding box analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BOUNDING BOX ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train_df['box_width'] = train_df['x2'] - train_df['x1']\n",
    "train_df['box_height'] = train_df['y2'] - train_df['y1']\n",
    "train_df['box_area'] = train_df['box_width'] * train_df['box_height']\n",
    "train_df['aspect_ratio'] = train_df['box_width'] / train_df['box_height']\n",
    "\n",
    "# Boxes per image statistics\n",
    "boxes_per_img = train_df.groupby('image_name').size()\n",
    "print(\"\\n--- Boxes Per Image Statistics ---\")\n",
    "print(f\"Average boxes per image: {boxes_per_img.mean():.2f}\")\n",
    "print(f\"Median boxes per image: {boxes_per_img.median():.0f}\")\n",
    "print(f\"Min boxes per image: {boxes_per_img.min()}\")\n",
    "print(f\"Max boxes per image: {boxes_per_img.max()}\")\n",
    "print(f\"Std boxes per image: {boxes_per_img.std():.2f}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot 1: Boxes per image histogram\n",
    "axes[0, 0].hist(boxes_per_img, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title(f'Products per Image (avg: {boxes_per_img.mean():.1f})')\n",
    "axes[0, 0].set_xlabel('Number of Products')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Box size scatter\n",
    "axes[0, 1].scatter(train_df['box_width'], train_df['box_height'], alpha=0.1, s=1)\n",
    "axes[0, 1].set_title('Box Size Distribution')\n",
    "axes[0, 1].set_xlabel('Width (px)')\n",
    "axes[0, 1].set_ylabel('Height (px)')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Box area histogram\n",
    "axes[1, 0].hist(train_df['box_area'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_title('Box Area Distribution')\n",
    "axes[1, 0].set_xlabel('Area (px²)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Box aspect ratio histogram\n",
    "axes[1, 1].hist(train_df['aspect_ratio'], bins=50, edgecolor='black', alpha=0.7, range=(0, 5))\n",
    "axes[1, 1].set_title('Box Aspect Ratio Distribution')\n",
    "axes[1, 1].set_xlabel('Aspect Ratio (width/height)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "YkOMXYFEKmdJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821,
     "output_embedded_package_id": "1NyzHGiQC2D6GOwbTOyDvA032Zy1U3ZNh"
    },
    "executionInfo": {
     "elapsed": 224496,
     "status": "ok",
     "timestamp": 1768699937967,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "YkOMXYFEKmdJ",
    "outputId": "913db32c-a061-4ccd-edb4-a15361624b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import tarfile\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample 2 random train images\n",
    "random_imgs = random.sample(train_df['image_name'].unique().tolist(), 2)\n",
    "\n",
    "tar_path = '/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed.tar.gz'\n",
    "tar = tarfile.open(tar_path, 'r:gz')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "for idx, img_name in enumerate(random_imgs):\n",
    "    # Extract image from tar\n",
    "    member = tar.getmember(f'SKU110K_fixed/images/{img_name}')\n",
    "    f = tar.extractfile(member)\n",
    "    img = Image.open(f)\n",
    "\n",
    "    # Get annotations\n",
    "    img_data = train_df[train_df['image_name'] == img_name]\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for _, row in img_data.iterrows():\n",
    "        draw.rectangle([row['x1'], row['y1'], row['x2'], row['y2']],\n",
    "                      outline='red', width=3)\n",
    "\n",
    "    # Display\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'{img_name}\\n{len(img_data)} products', fontsize=14, fontweight='bold')\n",
    "\n",
    "tar.close()\n",
    "\n",
    "# Save visualization\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/Deep Learning Project/sku110k_samples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4CgqW6xgRTXN",
   "metadata": {
    "id": "4CgqW6xgRTXN"
   },
   "source": [
    "# Model Training: YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I8hAR3ukRUjI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1974704,
     "status": "ok",
     "timestamp": 1767830728528,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "I8hAR3ukRUjI",
    "outputId": "9d6006bc-b518-4438-8a88-5ecdb6adf3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set extracted:\n",
      "  Images: 588 files\n",
      "  Labels: 588 files\n",
      "  Processed: 588\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "\n",
    "# Prepare validation directories\n",
    "val_img_dir = Path('/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val')\n",
    "val_label_dir = Path('/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/val')\n",
    "val_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "val_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Extract validation set\n",
    "tar_path = '/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed.tar.gz'\n",
    "tar = tarfile.open(tar_path, 'r:gz')\n",
    "\n",
    "val_imgs = val_df['image_name'].unique()\n",
    "processed = 0\n",
    "\n",
    "for img_name in val_imgs:\n",
    "    # Skip if already extracted\n",
    "    if (val_img_dir / img_name).exists() and (val_label_dir / f\"{Path(img_name).stem}.txt\").exists():\n",
    "          processed += 1\n",
    "          continue\n",
    "    try:\n",
    "        member = tar.getmember(f'SKU110K_fixed/images/{img_name}')\n",
    "        f = tar.extractfile(member)\n",
    "\n",
    "        # Save image\n",
    "        with open(val_img_dir / img_name, 'wb') as out:\n",
    "            out.write(f.read())\n",
    "\n",
    "        # Get annotations\n",
    "        img_data = val_df[val_df['image_name'] == img_name]\n",
    "        w = img_data.iloc[0]['image_width']\n",
    "        h = img_data.iloc[0]['image_height']\n",
    "\n",
    "        # Convert to YOLO format\n",
    "        labels = []\n",
    "        for _, row in img_data.iterrows():\n",
    "            x_center = ((row['x1'] + row['x2']) / 2) / w\n",
    "            y_center = ((row['y1'] + row['y2']) / 2) / h\n",
    "            width = (row['x2'] - row['x1']) / w\n",
    "            height = (row['y2'] - row['y1']) / h\n",
    "            labels.append(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "        # Save labels\n",
    "        (val_label_dir / f\"{Path(img_name).stem}.txt\").write_text('\\n'.join(labels))\n",
    "        processed += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "tar.close()\n",
    "\n",
    "print(f\"\\nValidation set extracted:\")\n",
    "print(f\"  Images: {len(list(val_img_dir.glob('*.jpg')))} files\")\n",
    "print(f\"  Labels: {len(list(val_label_dir.glob('*.txt')))} files\")\n",
    "print(f\"  Processed: {processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "PHIyrMayaxS9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26789623,
     "status": "ok",
     "timestamp": 1768764429580,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "PHIyrMayaxS9",
    "outputId": "59977473-af64-4d18-9616-bcc6c8f28bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BATCH ASSIGNMENT\n",
      "================================================================================\n",
      "Total images: 8219\n",
      "Total batches: 9\n",
      "Batches to train: 3\n",
      "Batch 1: 1000 images\n",
      "Batch 2: 1000 images\n",
      "Batch 3: 1000 images\n",
      "Batch 4: 1000 images\n",
      "Batch 5: 1000 images\n",
      "Batch 6: 1000 images\n",
      "Batch 7: 1000 images\n",
      "Batch 8: 1000 images\n",
      "Batch 9: 219 images\n",
      "\n",
      "================================================================================\n",
      "BATCH 1/3 - 1000 images\n",
      "Indices: 0 to 999\n",
      "================================================================================\n",
      "All images already extracted, skipping to training...\n",
      "  Images in dir: 1000 files\n",
      "  Labels in dir: 1000 files\n",
      "PRO TIP 💡 Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov5su.pt to 'yolov5su.pt': 100% ━━━━━━━━━━━━ 17.7MB 33.5MB/s 0.5s\n",
      "\n",
      "Training batch 1...\n",
      "Ultralytics 8.4.5 🚀 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/data_batch_1.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=batch_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/batch_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 5.7MB/s 0.1s\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2116435  ultralytics.nn.modules.head.Detect           [1, 16, None, [128, 256, 512]]\n",
      "YOLOv5s summary: 154 layers, 9,122,579 parameters, 9,122,563 gradients, 24.0 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ━━━━━━━━━━━━ 5.3MB 20.1MB/s 0.3s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 1.1±0.7 MB/s, size: 899.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/train_batch_1.cache... 1000 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1000/1000 199.7Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_1097.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_1134.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_1200.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_1250.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_1362.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_1392.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_1571.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_1822.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2313.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2362.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2447.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2651.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2702.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2858.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2903.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2946.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_2979.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_317.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_340.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_3489.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_3510.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_3678.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_3687.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_4085.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_4291.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_4635.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_4855.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_4860.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_5446.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_5645.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_5653.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_5754.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_5755.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_610.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_6172.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_6405.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_6422.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_667.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_6689.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_671.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_6784.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_6899.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_6971.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_7140.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_7393.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_7516.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_7636.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_7899.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_7949.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_7981.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_7994.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_8035.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_8108.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_1/train_8136.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.1 ms, read: 2.7±2.8 MB/s, size: 2137.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/val.cache... 588 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 588/588 44.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_0.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_115.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_127.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_166.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_172.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_190.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_2.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_209.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_214.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_223.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_280.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_290.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_292.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_295.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_324.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_332.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_334.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_394.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_406.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_413.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_47.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_471.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_49.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_510.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_525.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_547.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_582.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_72.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_74.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_82.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_85.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_89.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_95.jpg: corrupt JPEG restored and saved\n",
      "Plotting labels to /content/runs/batch_1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 1 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/content/runs/batch_1\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      5.77G      2.529      2.211      1.566       1639        640: 100% ━━━━━━━━━━━━ 125/125 2.1it/s 59.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 2.7s/it 1:39\n",
      "                   all        588      90968      0.609      0.531      0.566      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      5.07G      1.833     0.9941      1.227       2006        640: 100% ━━━━━━━━━━━━ 125/125 4.5it/s 27.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968      0.764      0.667      0.741      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      6.31G      1.701     0.8753      1.141       1531        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.809       0.71      0.794      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      6.31G      1.623     0.8279      1.094       2417        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.824       0.73      0.811      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      6.31G      1.579     0.7947      1.067       1693        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.834      0.753      0.827      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      6.31G      1.549     0.7736      1.049       2097        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.849       0.76      0.839      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      6.31G      1.525     0.7541       1.03       1885        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968      0.855      0.772      0.846      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      6.31G      1.506     0.7405      1.026       2258        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968      0.858      0.772      0.851      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      6.31G      1.486     0.7285      1.014       1907        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968       0.86      0.774      0.853       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      6.31G      1.477     0.7142      1.012       1456        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.864      0.782      0.859      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      6.31G      1.475     0.7125      1.004       2876        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.867      0.782       0.86      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      6.31G       1.47     0.7018     0.9985       1846        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968       0.87      0.778      0.859      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      6.31G      1.447      0.689      0.998       1800        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.872      0.782      0.865      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      6.34G      1.451     0.6929     0.9957       1738        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.6s\n",
      "                   all        588      90968      0.874       0.79      0.865      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      6.34G       1.43     0.6781     0.9877       1872        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.877      0.789      0.866      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      6.34G      1.432     0.6749     0.9897       2549        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.879       0.79      0.869      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      6.34G      1.448     0.6842     0.9861       2140        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.881      0.791      0.869      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      6.34G      1.443      0.684      0.987       2533        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.879      0.793      0.871      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      6.35G      1.416     0.6644     0.9802       1066        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.881      0.794      0.871      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      6.35G      1.418     0.6633     0.9811       1994        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.9it/s 7.6s\n",
      "                   all        588      90968      0.881      0.798      0.873       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      6.35G      1.409     0.6621     0.9785       3063        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.882      0.798      0.874      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      6.35G      1.402     0.6557     0.9762       1924        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.881      0.799      0.874      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      6.35G      1.398     0.6565     0.9743       2011        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968       0.88      0.801      0.873      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      6.35G      1.387     0.6487     0.9685       2082        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.882      0.798      0.874      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      6.35G        1.4     0.6488     0.9728       1679        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.886      0.799      0.876      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      6.35G        1.4     0.6496     0.9694       2237        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.885      0.799      0.877      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      6.35G      1.391      0.643      0.968       1706        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.884      0.801      0.877      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      6.35G      1.384     0.6413     0.9676       1400        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.883      0.795      0.872      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      6.35G      1.379     0.6388     0.9662       2007        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.883      0.804      0.879      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      6.35G      1.368     0.6276     0.9615       1920        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.886      0.807      0.879      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      6.35G      1.373      0.637     0.9654       1364        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.886      0.806      0.879      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      6.35G      1.372     0.6294      0.962       1455        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.884      0.802      0.877      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      6.35G      1.371     0.6313     0.9611       1749        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.887      0.805      0.878      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      6.35G      1.364     0.6242     0.9573       2029        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.9it/s 7.6s\n",
      "                   all        588      90968      0.889      0.806       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      6.35G      1.365     0.6288     0.9641       2265        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.886      0.806      0.877      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      6.35G      1.347     0.6171     0.9522       1345        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.9it/s 7.6s\n",
      "                   all        588      90968      0.886      0.804      0.876      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      6.35G      1.361     0.6229     0.9555       1799        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.888      0.806      0.878      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      6.35G      1.352     0.6177     0.9533       1650        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968       0.89      0.807       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      6.35G      1.345     0.6159     0.9549       2428        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.9it/s 7.6s\n",
      "                   all        588      90968      0.887      0.809      0.879      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      6.35G      1.351     0.6151     0.9546       1306        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.892      0.807      0.878      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      6.35G      1.346     0.6116     0.9504       1864        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.892      0.808       0.88      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      6.35G      1.347     0.6153     0.9554       2023        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.6s\n",
      "                   all        588      90968       0.89       0.81       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      6.35G      1.345     0.6123     0.9488       2570        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.891       0.81       0.88      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      6.35G      1.354     0.6143     0.9523       2107        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.891       0.81       0.88      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      6.35G      1.339     0.6069      0.948       2208        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.9it/s 7.6s\n",
      "                   all        588      90968       0.89       0.81       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      6.35G      1.342     0.6077     0.9503       1218        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.887      0.808      0.878      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      6.35G      1.322     0.6019     0.9454       1963        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.891      0.809      0.879      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      6.35G      1.336     0.6061     0.9466       2694        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.6s\n",
      "                   all        588      90968      0.893      0.808      0.881      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      6.35G       1.32     0.5992     0.9443       2301        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.892      0.807      0.881      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      6.35G      1.334     0.6048     0.9527       2224        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.9it/s 7.6s\n",
      "                   all        588      90968      0.891      0.808      0.881      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      6.38G      1.314      0.598     0.9471       2419        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.6s\n",
      "                   all        588      90968       0.89      0.813      0.881      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      6.38G      1.323     0.5979     0.9446       1498        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.888      0.814      0.881      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      6.38G      1.316     0.5973     0.9412       2015        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.9it/s 7.6s\n",
      "                   all        588      90968      0.892      0.811       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      6.38G      1.317     0.5969     0.9407       2194        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.889      0.812      0.881      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      6.38G      1.323      0.599     0.9477       2002        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.888       0.81       0.88      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      6.38G      1.318     0.5948     0.9437       2377        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.6s\n",
      "                   all        588      90968       0.89      0.811      0.879      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      6.38G      1.324      0.597     0.9461       2286        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.891       0.81      0.879      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      6.38G      1.319     0.5944     0.9444       1621        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968       0.89      0.812       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      6.38G      1.296     0.5821     0.9397       2068        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.9it/s 7.6s\n",
      "                   all        588      90968      0.892      0.811      0.879      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      6.38G      1.304     0.5879     0.9352       1554        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.892      0.809       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      6.38G      1.296     0.5816     0.9374       1617        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.892      0.811       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      6.38G       1.31     0.5894     0.9397       2121        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.891      0.813      0.881      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      6.38G      1.308     0.5889     0.9397       1904        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.892      0.812      0.881      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      6.38G      1.302      0.585     0.9395       1306        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.888      0.813       0.88      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      6.38G      1.314     0.5915     0.9444       1636        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.891      0.811      0.879      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      6.38G      1.296     0.5822     0.9358       1287        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.892      0.812       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      6.38G      1.306     0.5849     0.9362       1877        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.893      0.813       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      6.38G       1.29     0.5758     0.9323       1881        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.892      0.814       0.88      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      6.38G      1.292     0.5798     0.9375       2032        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.891      0.812      0.879      0.548\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 49, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "69 epochs completed in 0.682 hours.\n",
      "Optimizer stripped from /content/runs/batch_1/weights/last.pt, 18.5MB\n",
      "Optimizer stripped from /content/runs/batch_1/weights/best.pt, 18.5MB\n",
      "\n",
      "Validating /content/runs/batch_1/weights/best.pt...\n",
      "Ultralytics 8.4.5 🚀 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLOv5s summary (fused): 85 layers, 9,111,923 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 1.5it/s 25.1s\n",
      "                   all        588      90968      0.892      0.808      0.881      0.549\n",
      "Speed: 0.2ms preprocess, 3.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1m/content/runs/batch_1\u001b[0m\n",
      "Model saved: sku110k_batch_1.pt\n",
      "\n",
      "================================================================================\n",
      "BATCH 2/3 - 1000 images\n",
      "Indices: 1000 to 1999\n",
      "================================================================================\n",
      "Need to extract 1000 images...\n",
      "Progress: 100/1000 images processed\n",
      "Progress: 200/1000 images processed\n",
      "Progress: 300/1000 images processed\n",
      "Progress: 400/1000 images processed\n",
      "Progress: 500/1000 images processed\n",
      "Progress: 600/1000 images processed\n",
      "Progress: 700/1000 images processed\n",
      "Progress: 800/1000 images processed\n",
      "Progress: 900/1000 images processed\n",
      "Progress: 1000/1000 images processed\n",
      "\n",
      "Batch 2 extraction complete:\n",
      "  Newly extracted: 1000\n",
      "  Images in dir: 1000 files\n",
      "  Labels in dir: 1000 files\n",
      "\n",
      "Training batch 2...\n",
      "Ultralytics 8.4.5 🚀 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/data_batch_2.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/runs/batch_1/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=batch_2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/batch_2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2116435  ultralytics.nn.modules.head.Detect           [1, 16, None, [128, 256, 512]]\n",
      "YOLOv5s summary: 154 layers, 9,122,579 parameters, 9,122,563 gradients, 24.0 GFLOPs\n",
      "\n",
      "Transferred 427/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.3±0.0 ms, read: 252.7±52.3 MB/s, size: 834.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/train_batch_2... 999 images, 0 backgrounds, 1 corrupt: 100% ━━━━━━━━━━━━ 1000/1000 91.3it/s 10.9s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_1051.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_1375.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_1489.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2167.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2177.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2475.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2485.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2576.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2603.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2660.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_271.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2832.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2873.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_295.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_2994.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_3143.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_3325.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_349.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_3674.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_3698.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_386.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_4024.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_4261.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_4464.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_4524.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_4922.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_5080.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_5231.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_5605.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_588.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6031.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6077.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6099.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6230.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6373.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6417.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6590.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6605.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_679.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6809.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_686.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_6917.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_7204.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_756.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_7603.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_7801.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_7876.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_8078.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_814.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_924.jpg: ignoring corrupt image/label: image file is truncated (10 bytes not processed)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_2/train_934.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/train_batch_2.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.8±2.2 ms, read: 113.3±67.6 MB/s, size: 2016.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/val.cache... 588 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 588/588 32.5Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_0.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_115.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_127.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_166.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_172.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_190.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_2.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_209.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_214.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_223.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_280.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_290.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_292.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_295.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_324.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_332.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_334.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_394.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_406.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_413.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_47.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_471.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_49.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_510.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_525.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_547.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_582.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_72.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_74.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_82.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_85.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_89.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_95.jpg: corrupt JPEG restored and saved\n",
      "Plotting labels to /content/runs/batch_2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 1 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/content/runs/batch_2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      6.45G      1.434     0.6483      0.983       1793        640: 100% ━━━━━━━━━━━━ 125/125 3.1it/s 39.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968      0.889      0.814      0.886      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      6.71G      1.413     0.6468     0.9761       1994        640: 100% ━━━━━━━━━━━━ 125/125 4.5it/s 27.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.891      0.814      0.887      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100       5.4G      1.406     0.6484     0.9691       1333        640: 100% ━━━━━━━━━━━━ 125/125 4.7it/s 26.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.891      0.814      0.885      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      5.14G      1.403     0.6484     0.9718       2120        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968       0.89      0.811      0.881      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      7.33G      1.392     0.6474     0.9682       1624        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.892      0.808      0.881      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      7.33G      1.385     0.6393     0.9659       1690        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.891      0.814      0.886      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      7.33G      1.363     0.6292     0.9598       1719        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968      0.891      0.817      0.887      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      7.33G      1.376     0.6369     0.9616       1902        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968       0.89      0.816      0.883      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      7.33G      1.363     0.6266     0.9573       2566        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.891      0.816      0.884      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      7.33G      1.365     0.6312     0.9632       1376        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968       0.89      0.813      0.881      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      7.33G      1.371     0.6267     0.9569       2409        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.892      0.817      0.885      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      7.33G      1.357     0.6222     0.9536       1273        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968       0.89      0.813      0.883      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      7.33G       1.35     0.6194     0.9573       2417        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.894      0.817      0.886      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      7.36G      1.351     0.6177     0.9537       1718        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.891      0.815      0.882      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      5.86G       1.34     0.6123      0.948       1607        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968      0.892      0.817      0.883      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      6.01G       1.34     0.6125     0.9502       2270        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.894      0.814      0.884      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      5.95G       1.33     0.6083     0.9445       2110        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.894      0.816      0.885      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      6.09G      1.342     0.6118     0.9482       2076        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.893      0.818      0.883      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100       7.2G      1.331     0.6021     0.9468       1379        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968       0.89      0.815      0.882      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      5.47G      1.323     0.6024     0.9438       1493        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.894      0.819      0.884      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      5.39G      1.323     0.5998     0.9459       2589        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.894      0.817      0.883      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      6.61G      1.328     0.6039     0.9445       2132        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968      0.892      0.816      0.882      0.555\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 2, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "22 epochs completed in 0.214 hours.\n",
      "Optimizer stripped from /content/runs/batch_2/weights/last.pt, 18.5MB\n",
      "Optimizer stripped from /content/runs/batch_2/weights/best.pt, 18.5MB\n",
      "\n",
      "Validating /content/runs/batch_2/weights/best.pt...\n",
      "Ultralytics 8.4.5 🚀 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLOv5s summary (fused): 85 layers, 9,111,923 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 1.5it/s 25.1s\n",
      "                   all        588      90968      0.891      0.815      0.887      0.559\n",
      "Speed: 0.2ms preprocess, 3.6ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1m/content/runs/batch_2\u001b[0m\n",
      "Model saved: sku110k_batch_2.pt\n",
      "\n",
      "================================================================================\n",
      "BATCH 3/3 - 1000 images\n",
      "Indices: 2000 to 2999\n",
      "================================================================================\n",
      "Need to extract 1000 images...\n",
      "Progress: 100/1000 images processed\n",
      "Progress: 200/1000 images processed\n",
      "Progress: 300/1000 images processed\n",
      "Progress: 400/1000 images processed\n",
      "Progress: 500/1000 images processed\n",
      "Progress: 600/1000 images processed\n",
      "Progress: 700/1000 images processed\n",
      "Progress: 800/1000 images processed\n",
      "Progress: 900/1000 images processed\n",
      "Progress: 1000/1000 images processed\n",
      "\n",
      "Batch 3 extraction complete:\n",
      "  Newly extracted: 1000\n",
      "  Images in dir: 1000 files\n",
      "  Labels in dir: 1000 files\n",
      "\n",
      "Training batch 3...\n",
      "Ultralytics 8.4.5 🚀 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/data_batch_3.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/runs/batch_2/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=batch_3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/batch_3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2116435  ultralytics.nn.modules.head.Detect           [1, 16, None, [128, 256, 512]]\n",
      "YOLOv5s summary: 154 layers, 9,122,579 parameters, 9,122,563 gradients, 24.0 GFLOPs\n",
      "\n",
      "Transferred 427/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 298.6±104.1 MB/s, size: 1072.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/train_batch_3... 1000 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1000/1000 90.8it/s 11.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_1046.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_1158.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_1282.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_137.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_1538.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_1775.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_180.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_1852.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_1887.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_2171.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_2259.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_2435.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_2688.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_2859.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3089.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3104.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3237.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3335.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3366.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3454.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3660.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3764.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3845.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_3967.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_4080.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_412.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_4299.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_4426.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_4552.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_4634.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_470.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_4764.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_4930.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5051.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5141.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5201.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5363.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5420.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5499.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5506.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5531.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5595.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5756.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5775.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5876.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_5998.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_6026.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_6105.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_616.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_6261.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_6263.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_6926.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7105.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7217.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7266.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7456.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7631.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7639.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7664.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7709.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7724.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7840.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_7978.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_8200.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_899.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_939.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/train_batch_3/train_950.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/train_batch_3.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.8±3.0 ms, read: 90.3±10.0 MB/s, size: 2016.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/labels/val.cache... 588 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 588/588 39.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_0.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_115.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_127.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_166.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_172.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_190.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_2.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_209.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_214.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_223.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_280.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_290.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_292.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_295.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_324.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_332.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_334.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_394.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_406.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_413.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_47.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_471.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_49.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_510.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_525.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_547.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_582.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_72.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_74.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_82.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_85.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_89.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/val/val_95.jpg: corrupt JPEG restored and saved\n",
      "Plotting labels to /content/runs/batch_3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.002, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 1 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/content/runs/batch_3\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      4.81G      1.408     0.6472     0.9764       1860        640: 100% ━━━━━━━━━━━━ 125/125 3.2it/s 39.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.894      0.815      0.888      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      7.03G      1.385     0.6339     0.9716       2107        640: 100% ━━━━━━━━━━━━ 125/125 4.6it/s 27.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.892      0.816      0.888       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      7.03G      1.408     0.6457     0.9686       1653        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.9s\n",
      "                   all        588      90968       0.89      0.817      0.886      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      7.03G      1.378     0.6378     0.9692       1847        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.888      0.812      0.884      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      7.03G      1.395     0.6449     0.9736       1641        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.896      0.813      0.888      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      7.03G      1.368     0.6322      0.967       2148        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.896      0.817      0.889      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      7.03G      1.378     0.6323     0.9659       1686        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.891      0.816      0.886      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      7.03G      1.378     0.6354     0.9647       2142        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.892      0.817      0.887      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      7.03G      1.349       0.62     0.9569       2092        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.895      0.814      0.886      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      7.03G      1.351     0.6193     0.9599       1526        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.892      0.818      0.887      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      7.04G      1.358     0.6205     0.9568       2088        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.896      0.814      0.886      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      7.07G      1.368     0.6218     0.9592       2141        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.893      0.818      0.886      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100       7.1G      1.339     0.6166     0.9556       1967        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.6s\n",
      "                   all        588      90968      0.895      0.817      0.888      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100       7.1G      1.342     0.6145     0.9585       1659        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.894      0.816      0.886      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100       7.1G      1.334     0.6111     0.9486       1463        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.894       0.82      0.889      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100       7.1G      1.336     0.6099      0.952       2198        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.893       0.82      0.888      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100       7.1G      1.345     0.6099     0.9498       2421        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 25.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.893      0.817      0.885      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100       7.1G      1.329     0.6025     0.9503       2773        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.899      0.815      0.887      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100       7.1G      1.338     0.6083       0.95       1187        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.894      0.815      0.885      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100       7.1G      1.309     0.5951     0.9441       1813        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.896      0.818      0.888      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100       7.1G      1.323      0.598     0.9506       2923        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.6s\n",
      "                   all        588      90968      0.894      0.818      0.887      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100       7.1G      1.329     0.6024     0.9472       2013        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.892      0.821      0.888      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100       7.1G      1.317     0.5945     0.9486       2070        640: 100% ━━━━━━━━━━━━ 125/125 5.0it/s 25.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.8s\n",
      "                   all        588      90968      0.897       0.82      0.887      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100       7.1G      1.326     0.5996     0.9448       2246        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.8it/s 7.7s\n",
      "                   all        588      90968      0.895      0.818      0.888      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100       7.1G      1.317      0.595     0.9435       1662        640: 100% ━━━━━━━━━━━━ 125/125 4.8it/s 26.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.896      0.821      0.887      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100       7.1G      1.319     0.5928     0.9449       2426        640: 100% ━━━━━━━━━━━━ 125/125 4.9it/s 25.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 4.7it/s 7.8s\n",
      "                   all        588      90968      0.895      0.817      0.888      0.557\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 6, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "26 epochs completed in 0.249 hours.\n",
      "Optimizer stripped from /content/runs/batch_3/weights/last.pt, 18.5MB\n",
      "Optimizer stripped from /content/runs/batch_3/weights/best.pt, 18.5MB\n",
      "\n",
      "Validating /content/runs/batch_3/weights/best.pt...\n",
      "Ultralytics 8.4.5 🚀 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLOv5s summary (fused): 85 layers, 9,111,923 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 1.5it/s 25.0s\n",
      "                   all        588      90968      0.896      0.818      0.889      0.562\n",
      "Speed: 0.2ms preprocess, 3.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1m/content/runs/batch_3\u001b[0m\n",
      "Model saved: sku110k_batch_3.pt\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE\n",
      "================================================================================\n",
      "Total extracted images: 3000\n",
      "Total batches available: 9\n",
      "Batches trained: 3\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "# Base directory\n",
    "base_dir = Path('/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed')\n",
    "\n",
    "# Training parameters\n",
    "train_imgs = train_df['image_name'].unique().tolist()\n",
    "batch_size = 1000\n",
    "num_batches_total = len(train_imgs) // batch_size + (1 if len(train_imgs) % batch_size > 0 else 0)\n",
    "num_batches_to_train = 3  # Only train first 3 batches\n",
    "tar_path = '/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed.tar.gz'\n",
    "\n",
    "# Generate random batch assignments for ALL images\n",
    "random.seed(42)  # Fixed seed for reproducibility\n",
    "random.shuffle(train_imgs)\n",
    "\n",
    "# Assign ALL images to batches\n",
    "batch_assignments = {}\n",
    "for batch_idx in range(num_batches_total):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(train_imgs))\n",
    "    batch_assignments[batch_idx + 1] = {\n",
    "        'indices': list(range(start_idx, end_idx)),\n",
    "        'image_names': train_imgs[start_idx:end_idx]\n",
    "    }\n",
    "\n",
    "# Save complete batch assignment info\n",
    "with open(base_dir / 'batch_assignments.json', 'w') as f:\n",
    "    json.dump(batch_assignments, f, indent=2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BATCH ASSIGNMENT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total images: {len(train_imgs)}\")\n",
    "print(f\"Total batches: {num_batches_total}\")\n",
    "print(f\"Batches to train: {num_batches_to_train}\")\n",
    "for batch_num, info in batch_assignments.items():\n",
    "    print(f\"Batch {batch_num}: {len(info['image_names'])} images\")\n",
    "\n",
    "# Log file for extracted images\n",
    "extracted_log_path = base_dir / 'extracted_images.txt'\n",
    "\n",
    "# Load already extracted images if log exists\n",
    "extracted_images = set()\n",
    "if extracted_log_path.exists():\n",
    "    with open(extracted_log_path, 'r') as f:\n",
    "        extracted_images = set(line.strip().split(': ')[-1] for line in f if line.strip())\n",
    "\n",
    "# Thread locks for file operations\n",
    "tar_lock = Lock()\n",
    "log_lock = Lock()\n",
    "\n",
    "def extract_and_process_image(tar_obj, idx, img_name, train_df_local, img_dir, label_dir):\n",
    "    \"\"\"Extract and process a single image with its labels\"\"\"\n",
    "    try:\n",
    "        # Extract image from tar (needs lock for thread safety)\n",
    "        with tar_lock:\n",
    "            member = tar_obj.getmember(f'SKU110K_fixed/images/{img_name}')\n",
    "            f = tar_obj.extractfile(member)\n",
    "            img_data_bytes = f.read()\n",
    "\n",
    "        # Save image\n",
    "        with open(img_dir / img_name, 'wb') as out:\n",
    "            out.write(img_data_bytes)\n",
    "\n",
    "        # Get annotations for this image\n",
    "        img_data = train_df_local[train_df_local['image_name'] == img_name]\n",
    "        w = img_data.iloc[0]['image_width']\n",
    "        h = img_data.iloc[0]['image_height']\n",
    "\n",
    "        # Convert to YOLO format\n",
    "        labels = []\n",
    "        for _, row in img_data.iterrows():\n",
    "            x_center = ((row['x1'] + row['x2']) / 2) / w\n",
    "            y_center = ((row['y1'] + row['y2']) / 2) / h\n",
    "            width = (row['x2'] - row['x1']) / w\n",
    "            height = (row['y2'] - row['y1']) / h\n",
    "            labels.append(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "        # Save labels\n",
    "        (label_dir / f\"{Path(img_name).stem}.txt\").write_text('\\n'.join(labels))\n",
    "\n",
    "        return True, idx, img_name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_name}: {e}\")\n",
    "        return False, idx, img_name\n",
    "\n",
    "model = None\n",
    "tar = tarfile.open(tar_path, 'r:gz')\n",
    "\n",
    "# Only train the first num_batches_to_train batches\n",
    "for batch_num in range(1, num_batches_to_train + 1):\n",
    "    batch_imgs = batch_assignments[batch_num]['image_names']\n",
    "    batch_indices = batch_assignments[batch_num]['indices']\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"BATCH {batch_num}/{num_batches_to_train} - {len(batch_imgs)} images\")\n",
    "    print(f\"Indices: {batch_indices[0]} to {batch_indices[-1]}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Create separate directories for each batch\n",
    "    batch_img_dir = base_dir / f'images/train_batch_{batch_num}'\n",
    "    batch_label_dir = base_dir / f'labels/train_batch_{batch_num}'\n",
    "    batch_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    batch_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Filter images that need to be extracted\n",
    "    to_extract = [(idx, img) for idx, img in zip(batch_indices, batch_imgs)\n",
    "                  if img not in extracted_images]\n",
    "\n",
    "    if not to_extract:\n",
    "        print(\"All images already extracted, skipping to training...\")\n",
    "    else:\n",
    "        print(f\"Need to extract {len(to_extract)} images...\")\n",
    "\n",
    "        newly_extracted = []\n",
    "\n",
    "        # Multi-threaded extraction\n",
    "        max_workers = 8  # Number of parallel threads\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all extraction tasks\n",
    "            futures = {\n",
    "                executor.submit(extract_and_process_image, tar, idx, img_name, train_df, batch_img_dir, batch_label_dir): (idx, img_name)\n",
    "                for idx, img_name in to_extract\n",
    "            }\n",
    "\n",
    "            # Process completed tasks\n",
    "            completed = 0\n",
    "            for future in as_completed(futures):\n",
    "                success, idx, img_name = future.result()\n",
    "                if success:\n",
    "                    newly_extracted.append(f\"{idx}: {img_name}\")\n",
    "                    extracted_images.add(img_name)\n",
    "\n",
    "                completed += 1\n",
    "                if completed % 100 == 0:\n",
    "                    print(f\"Progress: {completed}/{len(to_extract)} images processed\")\n",
    "\n",
    "        # Batch write to log file to reduce I/O\n",
    "        if newly_extracted:\n",
    "            with log_lock:\n",
    "                with open(extracted_log_path, 'a') as f:\n",
    "                    f.write('\\n'.join(newly_extracted) + '\\n')\n",
    "\n",
    "        print(f\"\\nBatch {batch_num} extraction complete:\")\n",
    "        print(f\"  Newly extracted: {len(newly_extracted)}\")\n",
    "\n",
    "    print(f\"  Images in dir: {len(list(batch_img_dir.glob('*.jpg')))} files\")\n",
    "    print(f\"  Labels in dir: {len(list(batch_label_dir.glob('*.txt')))} files\")\n",
    "\n",
    "    # Create YAML config for this batch\n",
    "    yaml_content = f\"\"\"train: {batch_img_dir}\n",
    "val: {base_dir}/images/val\n",
    "nc: 1\n",
    "names: ['Product']\n",
    "\"\"\"\n",
    "    yaml_path = base_dir / f'data_batch_{batch_num}.yaml'\n",
    "    Path(yaml_path).write_text(yaml_content)\n",
    "\n",
    "    # Incremental training\n",
    "    if model is None:\n",
    "        model = YOLO('yolov5s.pt')\n",
    "    else:\n",
    "        prev_best = f'/content/runs/batch_{batch_num-1}/weights/best.pt'\n",
    "        model = YOLO(prev_best)\n",
    "\n",
    "    print(f\"\\nTraining batch {batch_num}...\")\n",
    "    model.train(\n",
    "        data=str(yaml_path),\n",
    "        epochs=100,\n",
    "        imgsz=640,\n",
    "        batch=8,\n",
    "        project='/content/runs',\n",
    "        name=f'batch_{batch_num}',\n",
    "        exist_ok=True,\n",
    "        patience=20\n",
    "    )\n",
    "\n",
    "    # Save model after each batch\n",
    "    batch_best = f'/content/runs/batch_{batch_num}/weights/best.pt'\n",
    "    shutil.copy(batch_best, base_dir / f'sku110k_batch_{batch_num}.pt')\n",
    "    print(f\"Model saved: sku110k_batch_{batch_num}.pt\")\n",
    "\n",
    "tar.close()\n",
    "\n",
    "# Save final model\n",
    "final_best = f'/content/runs/batch_{num_batches_to_train}/weights/best.pt'\n",
    "shutil.copy(final_best, base_dir / 'sku110k_final.pt')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total extracted images: {len(extracted_images)}\")\n",
    "print(f\"Total batches available: {num_batches_total}\")\n",
    "print(f\"Batches trained: {num_batches_to_train}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XdtTTDzug2zz",
   "metadata": {
    "id": "XdtTTDzug2zz"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7VELrXPbg44S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "10P45i8oLJ_q44WPp1ho8IRxaulsiuiFP"
    },
    "executionInfo": {
     "elapsed": 94055,
     "status": "ok",
     "timestamp": 1768768327359,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "7VELrXPbg44S",
    "outputId": "8152ef0a-0b76-4efd-abf6-bc6055e804ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import tarfile\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load trained model\n",
    "model = YOLO('/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/sku110k_final.pt')\n",
    "\n",
    "# Sample 2 random test images\n",
    "random_imgs = random.sample(test_df['image_name'].unique().tolist(), 2)\n",
    "\n",
    "tar_path = '/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed.tar.gz'\n",
    "tar = tarfile.open(tar_path, 'r:gz')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "for idx, img_name in enumerate(random_imgs):\n",
    "    # Extract image from tar\n",
    "    member = tar.getmember(f'SKU110K_fixed/images/{img_name}')\n",
    "    f = tar.extractfile(member)\n",
    "    img = Image.open(f)\n",
    "\n",
    "    # Get ground truth annotations\n",
    "    img_data = test_df[test_df['image_name'] == img_name]\n",
    "\n",
    "    # Draw ground truth boxes\n",
    "    img_gt = img.copy()\n",
    "    draw_gt = ImageDraw.Draw(img_gt)\n",
    "    for _, row in img_data.iterrows():\n",
    "        draw_gt.rectangle([row['x1'], row['y1'], row['x2'], row['y2']],\n",
    "                         outline='green', width=3)\n",
    "\n",
    "    # Display ground truth\n",
    "    axes[idx, 0].imshow(img_gt)\n",
    "    axes[idx, 0].axis('off')\n",
    "    axes[idx, 0].set_title(f'Ground Truth: {img_name}\\n{len(img_data)} products',\n",
    "                           fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Save temporary image for prediction\n",
    "    temp_path = f'/content/temp_{img_name}'\n",
    "    img.save(temp_path)\n",
    "\n",
    "    # Run prediction\n",
    "    results = model.predict(temp_path, conf=0.25, verbose=False)\n",
    "\n",
    "    # Draw prediction boxes\n",
    "    img_pred = img.copy()\n",
    "    draw_pred = ImageDraw.Draw(img_pred)\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = box.conf[0].cpu().numpy()\n",
    "        draw_pred.rectangle([x1, y1, x2, y2],\n",
    "                           outline='red', width=3)\n",
    "\n",
    "    # Display prediction\n",
    "    axes[idx, 1].imshow(img_pred)\n",
    "    axes[idx, 1].axis('off')\n",
    "    axes[idx, 1].set_title(f'Prediction: {img_name}\\n{len(results[0].boxes)} products detected',\n",
    "                           fontsize=14, fontweight='bold')\n",
    "\n",
    "tar.close()\n",
    "\n",
    "# Save visualization\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/Deep Learning Project/sku110k_test_comparison.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4RWNxrnYzE3n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 636705,
     "status": "ok",
     "timestamp": 1768770280595,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "4RWNxrnYzE3n",
    "outputId": "77f11425-7f57-4fa9-e2d8-09e2d1a54ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 50 test images...\n",
      "Extracted 50 images to /content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/pred\n",
      "\n",
      "Running predictions...\n",
      "\n",
      "Predictions complete:\n",
      "  Total images: 50\n",
      "  Total predictions: 7990\n",
      "  Average predictions per image: 159.80\n",
      "\n",
      "Prediction dataframe:\n",
      "     image_name          x1          y1          x2           y2   class  \\\n",
      "0  test_713.jpg  293.130157  988.754395  460.720276  1448.012085  object   \n",
      "1  test_713.jpg  106.500748  991.742981  281.903076  1465.118896  object   \n",
      "2  test_713.jpg  475.671539  981.222351  635.216736  1429.347656  object   \n",
      "3  test_713.jpg  648.951355  972.147461  796.954651  1411.723633  object   \n",
      "4  test_713.jpg  806.565247  968.047791  949.400452  1395.168457  object   \n",
      "\n",
      "   image_width  image_height  confidence  \n",
      "0         2448          3264    0.842926  \n",
      "1         2448          3264    0.841976  \n",
      "2         2448          3264    0.834142  \n",
      "3         2448          3264    0.826498  \n",
      "4         2448          3264    0.825421  \n",
      "\n",
      "Shape: (7990, 9)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load trained model\n",
    "model = YOLO('/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/sku110k_final.pt')\n",
    "\n",
    "# Sample 50 random test images\n",
    "random.seed(42)\n",
    "random_imgs = random.sample(test_df['image_name'].unique().tolist(), 50)\n",
    "\n",
    "# Prepare prediction directory\n",
    "pred_dir = Path('/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/pred')\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Extract images from tar\n",
    "tar_path = '/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed.tar.gz'\n",
    "tar = tarfile.open(tar_path, 'r:gz')\n",
    "\n",
    "print(\"Extracting 50 test images...\")\n",
    "for img_name in random_imgs:\n",
    "    member = tar.getmember(f'SKU110K_fixed/images/{img_name}')\n",
    "    f = tar.extractfile(member)\n",
    "\n",
    "    # Save image\n",
    "    with open(pred_dir / img_name, 'wb') as out:\n",
    "        out.write(f.read())\n",
    "\n",
    "tar.close()\n",
    "print(f\"Extracted {len(random_imgs)} images to {pred_dir}\")\n",
    "\n",
    "# Run predictions\n",
    "print(\"\\nRunning predictions...\")\n",
    "predictions = []\n",
    "\n",
    "for img_name in random_imgs:\n",
    "    img_path = pred_dir / img_name\n",
    "\n",
    "    # Run prediction\n",
    "    results = model.predict(str(img_path), conf=0.25, verbose=False)\n",
    "\n",
    "    # Get image dimensions\n",
    "    img_height, img_width = results[0].orig_shape\n",
    "\n",
    "    # Extract bounding boxes\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = box.conf[0].cpu().numpy()\n",
    "\n",
    "        predictions.append({\n",
    "            'image_name': img_name,\n",
    "            'x1': float(x1),\n",
    "            'y1': float(y1),\n",
    "            'x2': float(x2),\n",
    "            'y2': float(y2),\n",
    "            'class': 'object',\n",
    "            'image_width': img_width,\n",
    "            'image_height': img_height,\n",
    "            'confidence': float(conf)\n",
    "        })\n",
    "\n",
    "# Create predictions dataframe\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "\n",
    "print(f\"\\nPredictions complete:\")\n",
    "print(f\"  Total images: {len(random_imgs)}\")\n",
    "print(f\"  Total predictions: {len(pred_df)}\")\n",
    "print(f\"  Average predictions per image: {len(pred_df)/len(random_imgs):.2f}\")\n",
    "\n",
    "print(\"\\nPrediction dataframe:\")\n",
    "print(pred_df.head())\n",
    "print(f\"\\nShape: {pred_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "UxFMNpCL_wre",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1768772216676,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "UxFMNpCL_wre",
    "outputId": "96516492-848b-4a18-c667-14d9ecb1d16e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_df saved\n"
     ]
    }
   ],
   "source": [
    "pred_df.to_csv('/content/drive/MyDrive/Deep Learning Project/predictions.csv', index=False)\n",
    "print(\"pred_df saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dJ4zckqS7O5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407064,
     "status": "ok",
     "timestamp": 1768771548164,
     "user": {
      "displayName": "Yuhong Li",
      "userId": "05007242337654446538"
     },
     "user_tz": -60
    },
    "id": "dJ4zckqS7O5f",
    "outputId": "45fc88df-2ab3-490d-dacd-25c1f0e785ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping bounding boxes from predicted images...\n",
      "  Cropped: 100 boxes\n",
      "  Cropped: 200 boxes\n",
      "  Cropped: 300 boxes\n",
      "  Cropped: 400 boxes\n",
      "  Cropped: 500 boxes\n",
      "  Cropped: 600 boxes\n",
      "  Cropped: 700 boxes\n",
      "  Cropped: 800 boxes\n",
      "  Cropped: 900 boxes\n",
      "  Cropped: 1000 boxes\n",
      "  Cropped: 1100 boxes\n",
      "  Cropped: 1200 boxes\n",
      "  Cropped: 1300 boxes\n",
      "  Cropped: 1400 boxes\n",
      "  Cropped: 1500 boxes\n",
      "  Cropped: 1600 boxes\n",
      "  Cropped: 1700 boxes\n",
      "  Cropped: 1800 boxes\n",
      "  Cropped: 1900 boxes\n",
      "  Cropped: 2000 boxes\n",
      "  Cropped: 2100 boxes\n",
      "  Cropped: 2200 boxes\n",
      "  Cropped: 2300 boxes\n",
      "  Cropped: 2400 boxes\n",
      "  Cropped: 2500 boxes\n",
      "  Cropped: 2600 boxes\n",
      "  Cropped: 2700 boxes\n",
      "  Cropped: 2800 boxes\n",
      "  Cropped: 2900 boxes\n",
      "  Cropped: 3000 boxes\n",
      "  Cropped: 3100 boxes\n",
      "  Cropped: 3200 boxes\n",
      "  Cropped: 3300 boxes\n",
      "  Cropped: 3400 boxes\n",
      "  Cropped: 3500 boxes\n",
      "  Cropped: 3600 boxes\n",
      "  Cropped: 3700 boxes\n",
      "  Cropped: 3800 boxes\n",
      "  Cropped: 3900 boxes\n",
      "  Cropped: 4000 boxes\n",
      "  Cropped: 4100 boxes\n",
      "  Cropped: 4200 boxes\n",
      "  Cropped: 4300 boxes\n",
      "  Cropped: 4400 boxes\n",
      "  Cropped: 4500 boxes\n",
      "  Cropped: 4600 boxes\n",
      "  Cropped: 4700 boxes\n",
      "  Cropped: 4800 boxes\n",
      "  Cropped: 4900 boxes\n",
      "  Cropped: 5000 boxes\n",
      "  Cropped: 5100 boxes\n",
      "  Cropped: 5200 boxes\n",
      "  Cropped: 5300 boxes\n",
      "  Cropped: 5400 boxes\n",
      "  Cropped: 5500 boxes\n",
      "  Cropped: 5600 boxes\n",
      "  Cropped: 5700 boxes\n",
      "  Cropped: 5800 boxes\n",
      "  Cropped: 5900 boxes\n",
      "  Cropped: 6000 boxes\n",
      "  Cropped: 6100 boxes\n",
      "  Cropped: 6200 boxes\n",
      "  Cropped: 6300 boxes\n",
      "  Cropped: 6400 boxes\n",
      "  Cropped: 6500 boxes\n",
      "  Cropped: 6600 boxes\n",
      "  Cropped: 6700 boxes\n",
      "  Cropped: 6800 boxes\n",
      "  Cropped: 6900 boxes\n",
      "  Cropped: 7000 boxes\n",
      "  Cropped: 7100 boxes\n",
      "  Cropped: 7200 boxes\n",
      "  Cropped: 7300 boxes\n",
      "  Cropped: 7400 boxes\n",
      "  Cropped: 7500 boxes\n",
      "  Cropped: 7600 boxes\n",
      "  Cropped: 7700 boxes\n",
      "  Cropped: 7800 boxes\n",
      "  Cropped: 7900 boxes\n",
      "\n",
      "Cropping complete:\n",
      "  Total cropped boxes: 7990\n",
      "  Saved to: /content/drive/MyDrive/Deep Learning Project/cropped_predictions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Prepare cropped images directory\n",
    "crop_dir = Path('/content/drive/MyDrive/Deep Learning Project/cropped_predictions')\n",
    "crop_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pred_dir = Path('/content/drive/MyDrive/Deep Learning Project/SKU110K_fixed/images/pred')\n",
    "\n",
    "print(\"Cropping bounding boxes from predicted images...\")\n",
    "\n",
    "cropped_count = 0\n",
    "margin = 20  # Add margin around bounding box\n",
    "\n",
    "for _, row in pred_df.iterrows():\n",
    "    img_name = row['image_name']\n",
    "    img_path = pred_dir / img_name\n",
    "\n",
    "    # Open image\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Get bounding box coordinates with margin\n",
    "    x1 = max(0, int(row['x1']) - margin)\n",
    "    y1 = max(0, int(row['y1']) - margin)\n",
    "    x2 = min(img.width, int(row['x2']) + margin)\n",
    "    y2 = min(img.height, int(row['y2']) + margin)\n",
    "\n",
    "    # Crop image\n",
    "    cropped = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "    # Generate crop filename\n",
    "    img_stem = Path(img_name).stem\n",
    "    crop_filename = f\"{img_stem}_box_{cropped_count:04d}.jpg\"\n",
    "\n",
    "    # Save cropped image\n",
    "    cropped.save(crop_dir / crop_filename, quality=95)\n",
    "\n",
    "    cropped_count += 1\n",
    "\n",
    "    if cropped_count % 100 == 0:\n",
    "        print(f\"  Cropped: {cropped_count} boxes\")\n",
    "\n",
    "print(f\"\\nCropping complete:\")\n",
    "print(f\"  Total cropped boxes: {cropped_count}\")\n",
    "print(f\"  Saved to: {crop_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaae1cc",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Detection Performance\n",
    "\n",
    "**Final Metrics:**\n",
    "- Precision: 89.6%, Recall: 81.8%\n",
    "- mAP@0.5: 88.9%, mAP@0.5:0.95: 56.2%\n",
    "- Speed: 3.6ms inference per image\n",
    "\n",
    "**Training:**\n",
    "- YOLOv5s (9.1M parameters)\n",
    "- 117 total epochs across 3 incremental batches\n",
    "- cls_loss: 2.211 → 0.593 (73% reduction)\n",
    "- mAP@0.5: 56.6% → 88.9% (+32.3%)\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "**Dense Detection Challenge:**\n",
    "- 147 products/image average (max: 576)\n",
    "- Single-class \"object\" detection only\n",
    "- 7% over-detection rate (160 pred vs 147 avg truth)\n",
    "\n",
    "**Training Behavior:**\n",
    "- Strong initial learning (Run 1: 69 epochs)\n",
    "- Diminishing returns (Run 2-3: early stopping)\n",
    "- High starting mAP (56.6% epoch 1) from pretrained weights\n",
    "\n",
    "### Output for Pipeline\n",
    "\n",
    "**Generated Assets:**\n",
    "- 7,990 cropped product regions from 50 test images\n",
    "- Average 159.8 crops per shelf image\n",
    "- Bounding box CSV with coordinates and confidence (avg 0.83)\n",
    "- Model weights: `sku110k_batch_3.pt` (18.5MB)\n",
    "\n",
    "**Integration Limitations:**\n",
    "- Detection trained on SKU-110K shelf images\n",
    "- Classification trained on Grocery Store dataset\n",
    "- Different product distributions and feature spaces\n",
    "- No product type labels from detection stage\n",
    "- Expected degraded performance on cropped regions\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "- Unified dataset with consistent product labels\n",
    "- NMS parameter tuning to reduce over-detection\n",
    "- Multi-class detection for product categories\n",
    "- Address 81.8% recall (18% missed products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1cf11a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
